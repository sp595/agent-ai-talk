# Web Scraper Comune Codroipo

Scraper automatico per estrarre servizi dal sito comunale e generare knowledge base.

## ðŸš€ Quick Start

```bash
# 1. Installa dipendenze
pip install -r requirements.txt
playwright install chromium

# 2. Setup automatico (tutto in un comando)
python scraper/setup_full_pipeline.py
```

Questo script:
1. âœ… Scraping servizi dal sito
2. âœ… Generazione file Markdown
3. âœ… Upload su VAPI
4. âœ… Collegamento all'assistente

## ðŸ“‹ Script Disponibili

### `setup_full_pipeline.py` â­ - Setup Completo
Pipeline automatica completa.

```bash
python scraper/setup_full_pipeline.py
```

### `scrape_real.py` - Scraper
Estrae servizi dal sito reale.

```bash
python scraper/scrape_real.py
```
Output: `services_data_real.json`

### `generate_knowledge_base.py` - Generatore KB
Converte JSON in file Markdown.

```bash
python scraper/generate_knowledge_base.py
```
Output: `knowledge-base/*.md`

### `validate_data.py` - Validatore
Valida qualitÃ  dati estratti.

```bash
python scraper/validate_data.py
```

## ðŸ”„ Workflow Manuale

```bash
# 1. Scraping
python scraper/scrape_real.py

# 2. Genera KB
python scraper/generate_knowledge_base.py

# 3. Upload
python scripts/upload_knowledge_base.py

# 4. Collega
python scripts/link_knowledge_base.py
```

## ðŸ“ File Generati

```
scraper/
â””â”€â”€ services_data_real.json      # Dati estratti

knowledge-base/
â”œâ”€â”€ carta-identita.md
â”œâ”€â”€ certificato-residenza.md
â””â”€â”€ ...                          # Un file per servizio
```

## âš™ï¸ Configurazione

### Prerequisiti
```bash
# Dipendenze Python
pip install playwright beautifulsoup4 requests python-dotenv

# Browser Chromium
playwright install chromium

# File .env
echo "VAPI_API_KEY=your_key" > .env

# Assistant ID
echo "YOUR_ASSISTANT_ID" > .assistant-id
```

### Personalizzazione

**Modificare selettori scraping**
â†’ Edita `scraper/scrape_real.py` riga ~50

**Modificare template KB**
â†’ Edita `scraper/generate_knowledge_base.py` riga ~30

## ðŸ†˜ Troubleshooting

**"Playwright non installato"**
```bash
pip install playwright
playwright install chromium
```

**"Timeout durante scraping"**
â†’ Aumenta timeout in `scrape_real.py` (riga ~80)

**"Nessun servizio estratto"**
â†’ Selettori CSS potrebbero essere cambiati
â†’ Verifica struttura HTML del sito

**Scraping troppo lento**
â†’ Quando chiesto, rispondi 'N' a "estrarre dettagli"

## ðŸŽ¯ Best Practices

1. Backup `services_data_real.json` prima di riscrapare
2. Esegui `validate_data.py` dopo scraping
3. Testa con pochi servizi prima di full scraping
4. Ri-esegui periodicamente per dati aggiornati
